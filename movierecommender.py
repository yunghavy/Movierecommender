# -*- coding: utf-8 -*-
"""MovieRecommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LeNpkhtTY1wSkXxsaMvcVhzjN0VsdDTm
"""

# Recommneder system

# collaborative filtering - based on other people experiences and ratings
# content-based recommender -> done based on the customer experience


import pandas
user_item_details = pandas.read_csv("https://modcom.co.ke/datasets/file.csv")
user_item_details

# movie datasets

movie_details = pandas.read_csv("https://modcom.co.ke/datasets/Movie_Id_Titles.csv")
movie_details.head(50)

# merging two datasets
data = pandas.merge(user_item_details,movie_details, on='item_id')
data

# group by title , rating

data.groupby('title')['rating'].mean().sort_values(ascending=False)

data.groupby('title')['rating'].count().sort_values(ascending=False)

# store mean rating

mean_ratings = pandas.DataFrame(data.groupby('title')['rating'].mean())
mean_ratings

# column for number of ratings
mean_ratings['number_of_ratings'] = pandas.DataFrame(data.groupby('title')['rating'].count())
mean_ratings

# pivot table
# index, columns, values

pivot = data.pivot_table(index='user_id', columns='title', values='rating')
pivot

# movie selection

selected_movie = pivot['Batman (1989)']

similar = pivot.corrwith(selected_movie)
similar_df = pandas.DataFrame(similar, columns=['correlations'])
similar_df.sort_values('correlations', ascending=False)

# join similar_df with mean_ratings

similar_df = similar_df.join(mean_ratings['number_of_ratings'])
similar_df

# recommended movies
similar_df[similar_df['number_of_ratings'] > 200].sort_values('correlations', ascending=False).head(20)

# read new dataset containing movie attributes
movie_attributes = pandas.read_csv("https://modcom.co.ke/datasets/Movie_Attributes.csv")

# merge the new dataset with the existing dataset based on the 'item_id' column
data = pandas.merge(data, movie_attributes, on='item_id')

# create a new DataFrame with the 'item_id' and 'title' columns
movie_info = data[['item_id', 'title']].drop_duplicates()

# create a TF-IDF vectorizer to extract important keywords from the plot summary of each movie
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(stop_words='english')

# apply the TF-IDF vectorizer to the plot summary of each movie to obtain a sparse matrix
plot_matrix = tfidf.fit_transform(data['plot'])

# compute the cosine similarity between each pair of movies based on their sparse matrix
from sklearn.metrics.pairwise import cosine_similarity
cosine_similarities = cosine_similarity(plot_matrix)

# for a selected movie, compute the cosine similarity between that movie and all other movies
selected_movie_id = 123 # replace with the actual item_id of the selected movie
selected_movie_index = movie_info[movie_info['item_id'] == selected_movie_id].index[0]
similarities = list(enumerate(cosine_similarities[selected_movie_index]))

# combine the similarity scores from collaborative filtering and content-based filtering using a weighted average
alpha = 0.5 # weight for collaborative filtering
beta = 0.5 # weight for content-based filtering
combined_similarities = [(alpha * similar_df['correlations'][i]) + (beta * similarity) for i, similarity in similarities]

# recommend the top N movies based on the combined similarity scores
N = 20 # number of recommendations to generate
recommended_indices = [i[0] for i in sorted(enumerate(combined_similarities), key=lambda x:x[1], reverse=True)[1:N+1]]
recommended_movies = movie_info.iloc[recommended_indices]['title']